<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>自动微分系统实现 | ​Tech and Text Tales</title>
<meta name=keywords content="ml,tech"><meta name=description content="学习一下怎么实现机器学习框架🚀"><meta name=author content="Chang Liu"><link rel=canonical href=https://www.liuchang0812.com/posts/tech/ai/autograd/><link crossorigin=anonymous href=/assets/css/stylesheet.a4af005db3c63bc24ffc0dcec80afc2302cd35a372f77b50d97cd95a0ffee9d4.css integrity="sha256-pK8AXbPGO8JP/A3OyAr8IwLNNaNy93tQ2XzZWg/+6dQ=" rel="preload stylesheet" as=style><link rel=icon href=https://www.liuchang0812.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.liuchang0812.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://www.liuchang0812.com/favicon-32x32.png><link rel=apple-touch-icon href=https://www.liuchang0812.com/apple-touch-icon.png><link rel=mask-icon href=https://www.liuchang0812.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://www.liuchang0812.com/posts/tech/ai/autograd/><link rel=stylesheet href=/gitalk.css><script src=/gitalk.min.js></script><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=text/javascript async src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["[[","]]"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><meta property="og:title" content="自动微分系统实现"><meta property="og:description" content="学习一下怎么实现机器学习框架🚀"><meta property="og:type" content="article"><meta property="og:url" content="https://www.liuchang0812.com/posts/tech/ai/autograd/"><meta property="og:image" content="https://www.liuchang0812.com/pid/image.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-04-28T23:49:51+08:00"><meta property="article:modified_time" content="2025-04-28T23:49:51+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.liuchang0812.com/pid/image.png"><meta name=twitter:title content="自动微分系统实现"><meta name=twitter:description content="学习一下怎么实现机器学习框架🚀"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://www.liuchang0812.com/posts/"},{"@type":"ListItem","position":2,"name":"自动微分系统实现","item":"https://www.liuchang0812.com/posts/tech/ai/autograd/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"自动微分系统实现","name":"自动微分系统实现","description":"学习一下怎么实现机器学习框架🚀","keywords":["ml","tech"],"articleBody":"用过 pytorch 的小朋友都知道，只要调用一行 loss.backward(), 框架就会自动把所有变量的偏导数计算出来。这个看起来很神奇，一起来研究一下它是怎么实现的吧。本文简单介绍它的原理，然后提供一个简易的 CPP 实现帮忙理解。\n基础知识 链式法则 在导数计算方法里面有一个链式法则（大家应该都学过，但是忘得差不多了）。对于一个函数 $f(g(x)) $ 的导数等于 $ f'(g(x))*g'(x) $。也可又写成\n$$\\frac{\\partial z}{\\partial y} = \\frac{\\partial z}{\\partial u}*\\frac{\\partial u}{\\partial y}$$\n反向传导 有了上面的链式法则，我们就可以很巧妙的求导数了。假如我们有如下公式，要求 $\\frac{\\partial z}{\\partial x}$ 的值，就可又转换为 $\\frac{\\partial z}{\\partial y} * \\frac{\\partial y}{\\partial x}$\ny = x^3+x^2 z = 2*y-4 求导过程 把计算过程当成一个图来看，z 是最终的输出结点，看成是根结点。x 是输入结点，看成是叶子结点。就可以得到一个有向图。在自动求导的过程中，从根结点开始向下递归，z 结点的梯度是 $\\frac{\\partial z}{\\partial z}=1$。然后 y 结点是 z 的子结点，y 的结点就是 $\\frac{\\partial z}{\\partial y} * z.grad$。然后再计算 x 结点就是 $\\frac{\\partial z}{\\partial x} * z.grad = \\frac{\\partial y}{\\partial x} * y.grad$。\n可以看出来就是一个递归的过程。\n代码实现 这儿提供一个 deepseek 实现的简单版本\n#include #include #include // 定义操作类型枚举 typedef enum { OP_CONST, // 常量 OP_ADD, // 加法 OP_MUL, // 乘法 OP_POW // 幂运算 } OpType; // 微分值结构体 typedef struct Value { double data; // 数据值 double grad; // 梯度值 OpType op; // 操作类型 struct Value* prev[2]; // 前驱节点（最多两个输入） void (*backward)(struct Value*); // 反向传播函数 } Value; // 创建叶子节点（无操作） Value* create_leaf(double data) { Value* v = (Value*)malloc(sizeof(Value)); v-\u003edata = data; v-\u003egrad = 0.0; v-\u003eop = OP_CONST; v-\u003eprev[0] = v-\u003eprev[1] = NULL; v-\u003ebackward = NULL; return v; } // 加法运算 Value* add(Value* a, Value* b) { Value* v = (Value*)malloc(sizeof(Value)); v-\u003edata = a-\u003edata + b-\u003edata; v-\u003egrad = 0.0; v-\u003eop = OP_ADD; v-\u003eprev[0] = a; v-\u003eprev[1] = b; v-\u003ebackward = NULL; return v; } // 乘法运算 Value* mul(Value* a, Value* b) { Value* v = (Value*)malloc(sizeof(Value)); v-\u003edata = a-\u003edata * b-\u003edata; v-\u003egrad = 0.0; v-\u003eop = OP_MUL; v-\u003eprev[0] = a; v-\u003eprev[1] = b; v-\u003ebackward = NULL; return v; } // 幂运算 Value* pow_(Value* a, double exponent) { Value* v = (Value*)malloc(sizeof(Value)); v-\u003edata = pow(a-\u003edata, exponent); v-\u003egrad = 0.0; v-\u003eop = OP_POW; v-\u003eprev[0] = a; v-\u003eprev[1] = create_leaf(exponent); // 指数作为常量节点 v-\u003ebackward = NULL; return v; } // 反向传播实现 void backward(Value* v) { // 初始化输出梯度为1（dz/dz = 1） v-\u003egrad = 1.0; // 反向传播递归函数 void _backward(Value* v) { if (v == NULL) return; switch (v-\u003eop) { case OP_ADD: v-\u003eprev[0]-\u003egrad += v-\u003egrad * 1.0; // da/dx = 1 v-\u003eprev[1]-\u003egrad += v-\u003egrad * 1.0; // db/dy = 1 break; case OP_MUL: v-\u003eprev[0]-\u003egrad += v-\u003egrad * v-\u003eprev[1]-\u003edata; // da/dx = y v-\u003eprev[1]-\u003egrad += v-\u003egrad * v-\u003eprev[0]-\u003edata; // db/dy = x break; case OP_POW: { double exponent = v-\u003eprev[1]-\u003edata; v-\u003eprev[0]-\u003egrad += v-\u003egrad * exponent * pow(v-\u003eprev[0]-\u003edata, exponent-1); break; } case OP_CONST: break; } // 递归传播 _backward(v-\u003eprev[0]); _backward(v-\u003eprev[1]); } _backward(v); } // 示例使用 int main() { // 创建输入变量 Value* x = create_leaf(2.0); Value* y = create_leaf(3.0); // 构建计算图：z = x^2 * y + y + 2 Value* x_sq = pow_(x, 2); Value* term1 = mul(x_sq, y); Value* term2 = add(term1, y); Value* z = add(term2, create_leaf(2.0)); // 执行反向传播 backward(z); // 打印结果 printf(\"dz/dx = %.2f\\n\", x-\u003egrad); // 应输出 12.00 printf(\"dz/dy = %.2f\\n\", y-\u003egrad); // 应输出 5.00 // 释放内存（简化示例，实际需要更严谨的内存管理） free(x); free(y); free(x_sq); free(term1); free(term2); free(z); return 0; } ","wordCount":"923","inLanguage":"en","image":"https://www.liuchang0812.com/pid/image.png","datePublished":"2025-04-28T23:49:51+08:00","dateModified":"2025-04-28T23:49:51+08:00","author":[{"@type":"Person","name":"Chang Liu"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.liuchang0812.com/posts/tech/ai/autograd/"},"publisher":{"@type":"Organization","name":"​Tech and Text Tales","logo":{"@type":"ImageObject","url":"https://www.liuchang0812.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://www.liuchang0812.com/ accesskey=h title="​Tech and Text Tales (Alt + H)">​Tech and Text Tales</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://www.liuchang0812.com/posts title=📚文章><span>📚文章</span></a></li><li><a href=https://www.liuchang0812.com/search/ title=🔍搜索><span>🔍搜索</span></a></li><li><a href=https://www.liuchang0812.com/archives/ title=⏱时间轴><span>⏱时间轴</span></a></li><li><a href=https://www.liuchang0812.com/about/ title=🙋🏻‍♂️关于><span>🙋🏻‍♂️关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://www.liuchang0812.com/>Home</a>&nbsp;»&nbsp;<a href=https://www.liuchang0812.com/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">自动微分系统实现</h1></header><figure class=entry-cover><img loading=eager src=https://www.liuchang0812.com/pid/image.png alt></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%9f%ba%e7%a1%80%e7%9f%a5%e8%af%86 aria-label=基础知识>基础知识</a><ul><li><a href=#%e9%93%be%e5%bc%8f%e6%b3%95%e5%88%99 aria-label=链式法则>链式法则</a></li><li><a href=#%e5%8f%8d%e5%90%91%e4%bc%a0%e5%af%bc aria-label=反向传导>反向传导</a></li><li><a href=#%e6%b1%82%e5%af%bc%e8%bf%87%e7%a8%8b aria-label=求导过程>求导过程</a></li></ul></li><li><a href=#%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0 aria-label=代码实现>代码实现</a></li></ul></div></details></div><div class=post-content><p>用过 <code>pytorch</code> 的小朋友都知道，只要调用一行 <code>loss.backward()</code>, 框架就会自动把所有变量的偏导数计算出来。这个看起来很神奇，一起来研究一下它是怎么实现的吧。本文简单介绍它的原理，然后提供一个简易的 CPP 实现帮忙理解。</p><hr><h2 id=基础知识><strong>基础知识</strong><a hidden class=anchor aria-hidden=true href=#基础知识>#</a></h2><h3 id=链式法则>链式法则<a hidden class=anchor aria-hidden=true href=#链式法则>#</a></h3><p>在导数计算方法里面有一个链式法则（大家应该都学过，但是忘得差不多了）。对于一个函数 $f(g(x)) $ 的导数等于 $ f'(g(x))*g'(x) $。也可又写成</p><p>$$\frac{\partial z}{\partial y} = \frac{\partial z}{\partial u}*\frac{\partial u}{\partial y}$$</p><h3 id=反向传导>反向传导<a hidden class=anchor aria-hidden=true href=#反向传导>#</a></h3><p>有了上面的链式法则，我们就可以很巧妙的求导数了。假如我们有如下公式，要求 $\frac{\partial z}{\partial x}$ 的值，就可又转换为 $\frac{\partial z}{\partial y} * \frac{\partial y}{\partial x}$</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>y = x^<span style=color:#ff0;font-weight:700>3</span>+x^<span style=color:#ff0;font-weight:700>2</span>
</span></span><span style=display:flex><span>z = <span style=color:#ff0;font-weight:700>2</span>*y-<span style=color:#ff0;font-weight:700>4</span>
</span></span></code></pre></div><h3 id=求导过程>求导过程<a hidden class=anchor aria-hidden=true href=#求导过程>#</a></h3><p>把计算过程当成一个图来看，z 是最终的输出结点，看成是根结点。x 是输入结点，看成是叶子结点。就可以得到一个有向图。在自动求导的过程中，从根结点开始向下递归，z 结点的梯度是 $\frac{\partial z}{\partial z}=1$。然后 y 结点是 z 的子结点，y 的结点就是 $\frac{\partial z}{\partial y} * z.grad$。然后再计算 x 结点就是 $\frac{\partial z}{\partial x} * z.grad = \frac{\partial y}{\partial x} * y.grad$。</p><p>可以看出来就是一个递归的过程。</p><h2 id=代码实现>代码实现<a hidden class=anchor aria-hidden=true href=#代码实现>#</a></h2><p>这儿提供一个 deepseek 实现的简单版本</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#0f0;font-weight:700>#include</span> <span style=color:#0f0;font-weight:700>&lt;stdio.h&gt;</span><span style=color:#0f0;font-weight:700>
</span></span></span><span style=display:flex><span><span style=color:#0f0;font-weight:700>#include</span> <span style=color:#0f0;font-weight:700>&lt;stdlib.h&gt;</span><span style=color:#0f0;font-weight:700>
</span></span></span><span style=display:flex><span><span style=color:#0f0;font-weight:700>#include</span> <span style=color:#0f0;font-weight:700>&lt;math.h&gt;</span><span style=color:#0f0;font-weight:700>
</span></span></span><span style=display:flex><span><span style=color:#0f0;font-weight:700></span>
</span></span><span style=display:flex><span><span style=color:#007f7f>// 定义操作类型枚举
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span><span style=color:#fff;font-weight:700>typedef</span> <span style=color:#fff;font-weight:700>enum</span> {
</span></span><span style=display:flex><span>    OP_CONST,   <span style=color:#007f7f>// 常量
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    OP_ADD,     <span style=color:#007f7f>// 加法
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    OP_MUL,     <span style=color:#007f7f>// 乘法
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    OP_POW      <span style=color:#007f7f>// 幂运算
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>} OpType;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f>// 微分值结构体
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span><span style=color:#fff;font-weight:700>typedef</span> <span style=color:#fff;font-weight:700>struct</span> Value {
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>double</span> data;        <span style=color:#007f7f>// 数据值
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    <span style=color:#fff;font-weight:700>double</span> grad;        <span style=color:#007f7f>// 梯度值
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    OpType op;          <span style=color:#007f7f>// 操作类型
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    <span style=color:#fff;font-weight:700>struct</span> Value* prev[<span style=color:#ff0;font-weight:700>2</span>]; <span style=color:#007f7f>// 前驱节点（最多两个输入）
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    <span style=color:#fff;font-weight:700>void</span> (*backward)(<span style=color:#fff;font-weight:700>struct</span> Value*); <span style=color:#007f7f>// 反向传播函数
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>} Value;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f>// 创建叶子节点（无操作）
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>Value* create_leaf(<span style=color:#fff;font-weight:700>double</span> data) {
</span></span><span style=display:flex><span>    Value* v = (Value*)malloc(<span style=color:#fff;font-weight:700>sizeof</span>(Value));
</span></span><span style=display:flex><span>    v-&gt;data = data;
</span></span><span style=display:flex><span>    v-&gt;grad = <span style=color:#ff0;font-weight:700>0.0</span>;
</span></span><span style=display:flex><span>    v-&gt;op = OP_CONST;
</span></span><span style=display:flex><span>    v-&gt;prev[<span style=color:#ff0;font-weight:700>0</span>] = v-&gt;prev[<span style=color:#ff0;font-weight:700>1</span>] = <span style=color:#fff;font-weight:700>NULL</span>;
</span></span><span style=display:flex><span>    v-&gt;backward = <span style=color:#fff;font-weight:700>NULL</span>;
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>return</span> v;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f>// 加法运算
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>Value* add(Value* a, Value* b) {
</span></span><span style=display:flex><span>    Value* v = (Value*)malloc(<span style=color:#fff;font-weight:700>sizeof</span>(Value));
</span></span><span style=display:flex><span>    v-&gt;data = a-&gt;data + b-&gt;data;
</span></span><span style=display:flex><span>    v-&gt;grad = <span style=color:#ff0;font-weight:700>0.0</span>;
</span></span><span style=display:flex><span>    v-&gt;op = OP_ADD;
</span></span><span style=display:flex><span>    v-&gt;prev[<span style=color:#ff0;font-weight:700>0</span>] = a;
</span></span><span style=display:flex><span>    v-&gt;prev[<span style=color:#ff0;font-weight:700>1</span>] = b;
</span></span><span style=display:flex><span>    v-&gt;backward = <span style=color:#fff;font-weight:700>NULL</span>;
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>return</span> v;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f>// 乘法运算
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>Value* mul(Value* a, Value* b) {
</span></span><span style=display:flex><span>    Value* v = (Value*)malloc(<span style=color:#fff;font-weight:700>sizeof</span>(Value));
</span></span><span style=display:flex><span>    v-&gt;data = a-&gt;data * b-&gt;data;
</span></span><span style=display:flex><span>    v-&gt;grad = <span style=color:#ff0;font-weight:700>0.0</span>;
</span></span><span style=display:flex><span>    v-&gt;op = OP_MUL;
</span></span><span style=display:flex><span>    v-&gt;prev[<span style=color:#ff0;font-weight:700>0</span>] = a;
</span></span><span style=display:flex><span>    v-&gt;prev[<span style=color:#ff0;font-weight:700>1</span>] = b;
</span></span><span style=display:flex><span>    v-&gt;backward = <span style=color:#fff;font-weight:700>NULL</span>;
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>return</span> v;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f>// 幂运算
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>Value* pow_(Value* a, <span style=color:#fff;font-weight:700>double</span> exponent) {
</span></span><span style=display:flex><span>    Value* v = (Value*)malloc(<span style=color:#fff;font-weight:700>sizeof</span>(Value));
</span></span><span style=display:flex><span>    v-&gt;data = pow(a-&gt;data, exponent);
</span></span><span style=display:flex><span>    v-&gt;grad = <span style=color:#ff0;font-weight:700>0.0</span>;
</span></span><span style=display:flex><span>    v-&gt;op = OP_POW;
</span></span><span style=display:flex><span>    v-&gt;prev[<span style=color:#ff0;font-weight:700>0</span>] = a;
</span></span><span style=display:flex><span>    v-&gt;prev[<span style=color:#ff0;font-weight:700>1</span>] = create_leaf(exponent); <span style=color:#007f7f>// 指数作为常量节点
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    v-&gt;backward = <span style=color:#fff;font-weight:700>NULL</span>;
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>return</span> v;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f>// 反向传播实现
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span><span style=color:#fff;font-weight:700>void</span> backward(Value* v) {
</span></span><span style=display:flex><span>    <span style=color:#007f7f>// 初始化输出梯度为1（dz/dz = 1）
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    v-&gt;grad = <span style=color:#ff0;font-weight:700>1.0</span>;
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#007f7f>// 反向传播递归函数
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    <span style=color:#fff;font-weight:700>void</span> _backward(Value* v) {
</span></span><span style=display:flex><span>        <span style=color:#fff;font-weight:700>if</span> (v == <span style=color:#fff;font-weight:700>NULL</span>) <span style=color:#fff;font-weight:700>return</span>;
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#fff;font-weight:700>switch</span> (v-&gt;op) {
</span></span><span style=display:flex><span>            <span style=color:#fff;font-weight:700>case</span> OP_ADD:
</span></span><span style=display:flex><span>                v-&gt;prev[<span style=color:#ff0;font-weight:700>0</span>]-&gt;grad += v-&gt;grad * <span style=color:#ff0;font-weight:700>1.0</span>; <span style=color:#007f7f>// da/dx = 1
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>                v-&gt;prev[<span style=color:#ff0;font-weight:700>1</span>]-&gt;grad += v-&gt;grad * <span style=color:#ff0;font-weight:700>1.0</span>; <span style=color:#007f7f>// db/dy = 1
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>                <span style=color:#fff;font-weight:700>break</span>;
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>            <span style=color:#fff;font-weight:700>case</span> OP_MUL:
</span></span><span style=display:flex><span>                v-&gt;prev[<span style=color:#ff0;font-weight:700>0</span>]-&gt;grad += v-&gt;grad * v-&gt;prev[<span style=color:#ff0;font-weight:700>1</span>]-&gt;data; <span style=color:#007f7f>// da/dx = y
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>                v-&gt;prev[<span style=color:#ff0;font-weight:700>1</span>]-&gt;grad += v-&gt;grad * v-&gt;prev[<span style=color:#ff0;font-weight:700>0</span>]-&gt;data; <span style=color:#007f7f>// db/dy = x
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>                <span style=color:#fff;font-weight:700>break</span>;
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>            <span style=color:#fff;font-weight:700>case</span> OP_POW: {
</span></span><span style=display:flex><span>                <span style=color:#fff;font-weight:700>double</span> exponent = v-&gt;prev[<span style=color:#ff0;font-weight:700>1</span>]-&gt;data;
</span></span><span style=display:flex><span>                v-&gt;prev[<span style=color:#ff0;font-weight:700>0</span>]-&gt;grad += v-&gt;grad * exponent * pow(v-&gt;prev[<span style=color:#ff0;font-weight:700>0</span>]-&gt;data, exponent-<span style=color:#ff0;font-weight:700>1</span>);
</span></span><span style=display:flex><span>                <span style=color:#fff;font-weight:700>break</span>;
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#fff;font-weight:700>case</span> OP_CONST:
</span></span><span style=display:flex><span>                <span style=color:#fff;font-weight:700>break</span>;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#007f7f>// 递归传播
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>        _backward(v-&gt;prev[<span style=color:#ff0;font-weight:700>0</span>]);
</span></span><span style=display:flex><span>        _backward(v-&gt;prev[<span style=color:#ff0;font-weight:700>1</span>]);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    _backward(v);
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#007f7f>// 示例使用
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span><span style=color:#fff;font-weight:700>int</span> main() {
</span></span><span style=display:flex><span>    <span style=color:#007f7f>// 创建输入变量
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    Value* x = create_leaf(<span style=color:#ff0;font-weight:700>2.0</span>);
</span></span><span style=display:flex><span>    Value* y = create_leaf(<span style=color:#ff0;font-weight:700>3.0</span>);
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#007f7f>// 构建计算图：z = x^2 * y + y + 2
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    Value* x_sq = pow_(x, <span style=color:#ff0;font-weight:700>2</span>);
</span></span><span style=display:flex><span>    Value* term1 = mul(x_sq, y);
</span></span><span style=display:flex><span>    Value* term2 = add(term1, y);
</span></span><span style=display:flex><span>    Value* z = add(term2, create_leaf(<span style=color:#ff0;font-weight:700>2.0</span>));
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#007f7f>// 执行反向传播
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    backward(z);
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#007f7f>// 打印结果
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    printf(<span style=color:#0ff;font-weight:700>&#34;dz/dx = %.2f</span><span style=color:#0ff;font-weight:700>\n</span><span style=color:#0ff;font-weight:700>&#34;</span>, x-&gt;grad); <span style=color:#007f7f>// 应输出 12.00
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    printf(<span style=color:#0ff;font-weight:700>&#34;dz/dy = %.2f</span><span style=color:#0ff;font-weight:700>\n</span><span style=color:#0ff;font-weight:700>&#34;</span>, y-&gt;grad); <span style=color:#007f7f>// 应输出 5.00
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    
</span></span><span style=display:flex><span>    <span style=color:#007f7f>// 释放内存（简化示例，实际需要更严谨的内存管理）
</span></span></span><span style=display:flex><span><span style=color:#007f7f></span>    free(x); free(y); free(x_sq);
</span></span><span style=display:flex><span>    free(term1); free(term2); free(z);
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#fff;font-weight:700>return</span> <span style=color:#ff0;font-weight:700>0</span>;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://www.liuchang0812.com/tags/ml/>Ml</a></li><li><a href=https://www.liuchang0812.com/tags/tech/>Tech</a></li></ul><nav class=paginav><a class=next href=https://www.liuchang0812.com/posts/tech/pid/><span class=title>Next »</span><br><span>控制论算法 PID</span></a></nav></footer><div id=gitalk-container></div><script>const gitalk=new Gitalk({clientID:"Ov23lidbgsgFTPNkhH1G",clientSecret:"a86118e270267b825a0ae65cbaa4b1640df5d3b7",repo:"liuchang0812.github.io",owner:"liuchang0812",admin:["liuchang0812"],id:location.pathname,distractionFreeMode:!1});gitalk.render("gitalk-container")</script></article></main><footer class=footer><span>&copy; 2025 <a href=https://www.liuchang0812.com/>​Tech and Text Tales</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>